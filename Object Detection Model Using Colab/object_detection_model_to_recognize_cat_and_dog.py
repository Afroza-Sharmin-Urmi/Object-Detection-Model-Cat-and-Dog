# -*- coding: utf-8 -*-
"""Object Detection Model to Recognize cat and Dog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EU3T5amBt5pLEgfCneqAtsXvDV52UKEM

##Installing Requirements

*   Initially we are going to clone "yolov5" (we're using YOLOv5 instead of  YOLOv8 because YOLOv5 is built on the PyTorch framework, making it easy for developers to use and deploy). Install and import all sort of required packages that we will needed throughout our model implementation. Initial steps are like:


*   Importing annotated image dataset(Contains dog and cat image).
*   Exporting our dataset to YOLOv5
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ultralytics/yolov5
# %cd yolov5
# %pip install -qr requirements.txt
# %pip install -q roboflow

import torch
import os
from  IPython.display import Image, clear_output
print(f"Setup complete. Using torch{torch.__version__}({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})")

"""##Assemble Our Dataset

*   Installing roboflow as we annotated dataset on Roboflow.

*   The dataset was preprocessed, augmentated and generated from the given dataset in Roboflow.
*   Defining API from roboflow.
*   Getting Dataset Directory from os enviroment.
*   Downloading and Extracting annotated dataset from Roboflow using API.
"""

#uncomment below line to install roboflow

#pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="YOUR API KEY HERE")

os.environ["DATASET_DIRECTORY"] = "/content/datasets"

from roboflow import Roboflow
rf = Roboflow(api_key="DPoFLaGRx96aoZgimwaX")
project = rf.workspace("urmi").project("object-detection-model-to-recognize-cat-and-dog")
dataset = project.version(2).download("yolov5")

"""##Train Model using Annotated Train Data


*   Here images are given 640x640 size, taking image as 640.
*   Total 16 batch
*   Total 100 no of epochs running to simultaneously train the model.
*   Locating the dataset, our dataset location is saved in dataset.location
*   Trained model saved in yolov5 for further implementation.
*   Specify a path to weights to start transfer learning, we choose generic pretrained checkpoint.
*   Cache images for faster training.





"""

!python train.py --img 640 --batch 16 --epochs 80 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache --name yolov5s_results

"""##Evaluate YOLOv5 Detector Performance

---


Training loss and performance metrics are saved to Tensorboard and to a logfile. 

*   Loading Tensorboard to show performance measurement score graph of the model.
*   As we can analyze that performance metrices score of our model are increasing in the given graph (Accuracy, Precision, recall).
*   We can also find validation loss of box, object, and class from the scalars
*   Loss decreasing with each incremental epochs.



"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir runs

"""## Run Inference with Trained Weights
Running inference with a pretrained checkpoints on context of test/images folder downloaded from Roboflow.
"""

!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 640 --conf 0.1 --source {dataset.location}/test/images

"""## Test model using Test Dataset

Before move into testing phase, we must be careful about the path above.  
"""

#display inference on all the test images
import glob
from IPython.display import Image, display

for imageName in glob.glob('runs/detect/exp/*.jpg'):
    display(Image(filename = imageName))
    print("\n")

"""## Run Validation 


*   Summarizing Class of image, total instances
*   Generating performance measurement scores 
*   Getting model Performance from precision, recall scores
*   Model class, object, bounding box loss analysis(which we can also find in tesnorboard dashboard above).


"""

!python val.py --weights runs/train/yolov5s_results/weights/best.pt --data /content/datasets/Object-Detection-Model-to-Recognize-Cat-and-Dog--2/data.yaml  --img 640 --iou 0.65

!ls runs/train/yolov5s_results

"""## Traditional Graph Analysis(precision-Confidence Curve)"""

from utils.plots import plot_results
Image(filename = 'runs/train/yolov5s_results/results.png', width = 1000)
Image(filename = 'runs/train/yolov5s_results/P_curve.png', width = 1000)

"""## Test model performance using random image from internet


*   We can upload random image and copy path in the source to test our model performance randomly.
*   As below, we can see our model did pretty well on detecting cat and dog on random image (performance of  model can vary based on environment and set up).


"""

!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 640 --conf 0.1 --source /content/images.jpg

for imageName in glob.glob('runs/detect/exp3/*.jpg'):
    display(Image(filename = imageName))
    print("\n")

"""## save the Model 

*   We are saving our model so that we can build API in streamlit using .pt file for common usages of our model. 
*  Convenient  User Interface to understand our work and implemented model.


"""

#export model's weights

from google.colab import files
files.download('./runs/train/yolov5s_results/weights/best.pt')
files.download('runs/train/yolov5s_results')